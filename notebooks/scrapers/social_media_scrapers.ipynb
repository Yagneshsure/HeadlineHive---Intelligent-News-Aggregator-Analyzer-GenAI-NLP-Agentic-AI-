{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed2954c",
   "metadata": {},
   "source": [
    "# Twitter scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb5bc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22AI%20OR%20Artificial%20Intelligence%20since%3A2025-08-15%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D: blocked (404)\n",
      "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22AI%20OR%20Artificial%20Intelligence%20since%3A2025-08-15%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.\n",
      "Errors: blocked (404), blocked (404), blocked (404), blocked (404)\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22AI%20OR%20Artificial%20Intelligence%20since%3A2025-08-15%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(tweets)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df_twitter \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_twitter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAI OR Artificial Intelligence since:2025-08-15\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_twitter\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m, in \u001b[0;36mscrape_twitter\u001b[1;34m(query, limit)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mscrape_twitter\u001b[39m(query, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m      5\u001b[0m     tweets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sntwitter\u001b[38;5;241m.\u001b[39mTwitterSearchScraper(query)\u001b[38;5;241m.\u001b[39mget_items()):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m limit:\n\u001b[0;32m      8\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yagne\\OneDrive\\Desktop\\project s\\Co-projects\\HeadlineHive-Intelligent-News-Aggregator-Analyzer-GenAI-NLP-Agentic-AI-\\venv310\\lib\\site-packages\\snscrape\\modules\\twitter.py:1763\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1760\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m: variables, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m: features}\n\u001b[0;32m   1761\u001b[0m paginationParams \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m: paginationVariables, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m: features}\n\u001b[1;32m-> 1763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_api_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline\u001b[39m\u001b[38;5;124m'\u001b[39m, _TwitterAPIType\u001b[38;5;241m.\u001b[39mGRAPHQL, params, paginationParams, cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor, instructionsPath \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_by_raw_query\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_timeline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m   1764\u001b[0m \t\u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphql_timeline_instructions_to_tweets(obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_by_raw_query\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_timeline\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeline\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\yagne\\OneDrive\\Desktop\\project s\\Co-projects\\HeadlineHive-Intelligent-News-Aggregator-Analyzer-GenAI-NLP-Agentic-AI-\\venv310\\lib\\site-packages\\snscrape\\modules\\twitter.py:915\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[1;34m(self, endpoint, apiType, params, paginationParams, cursor, direction, instructionsPath)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieving scroll page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcursor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 915\u001b[0m \tobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_api_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapiType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreqParams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \t\u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    918\u001b[0m \t\u001b[38;5;66;03m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yagne\\OneDrive\\Desktop\\project s\\Co-projects\\HeadlineHive-Intelligent-News-Aggregator-Analyzer-GenAI-NLP-Agentic-AI-\\venv310\\lib\\site-packages\\snscrape\\modules\\twitter.py:886\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[1;34m(self, endpoint, apiType, params, instructionsPath)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apiType \u001b[38;5;129;01mis\u001b[39;00m _TwitterAPIType\u001b[38;5;241m.\u001b[39mGRAPHQL:\n\u001b[0;32m    885\u001b[0m \tparams \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlencode({k: json\u001b[38;5;241m.\u001b[39mdumps(v, separators \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems()}, quote_via \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mquote)\n\u001b[1;32m--> 886\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apiHeaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponseOkCallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_api_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapiType\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mapiType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39m_snscrapeObj\n",
      "File \u001b[1;32mc:\\Users\\yagne\\OneDrive\\Desktop\\project s\\Co-projects\\HeadlineHive-Intelligent-News-Aggregator-Analyzer-GenAI-NLP-Agentic-AI-\\venv310\\lib\\site-packages\\snscrape\\base.py:275\u001b[0m, in \u001b[0;36mScraper._get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 275\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yagne\\OneDrive\\Desktop\\project s\\Co-projects\\HeadlineHive-Intelligent-News-Aggregator-Analyzer-GenAI-NLP-Agentic-AI-\\venv310\\lib\\site-packages\\snscrape\\base.py:271\u001b[0m, in \u001b[0;36mScraper._request\u001b[1;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[0;32m    269\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39mfatal(msg)\n\u001b[0;32m    270\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39mfatal(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mErrors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 271\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m ScraperException(msg)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReached unreachable code\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mScraperException\u001b[0m: 4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22AI%20OR%20Artificial%20Intelligence%20since%3A2025-08-15%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up."
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_twitter(query, limit=50):\n",
    "    tweets = []\n",
    "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "        if i >= limit:\n",
    "            break\n",
    "        tweets.append({\n",
    "            \"date\": tweet.date,\n",
    "            \"id\": tweet.id,\n",
    "            \"content\": tweet.content,\n",
    "            \"username\": tweet.user.username,\n",
    "            \"retweets\": tweet.retweetCount,\n",
    "            \"likes\": tweet.likeCount,\n",
    "        })\n",
    "    return pd.DataFrame(tweets)\n",
    "\n",
    "# Example usage\n",
    "df_twitter = scrape_twitter(\"AI OR Artificial Intelligence since:2025-08-15\")\n",
    "print(df_twitter.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82987048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snscrape"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached snscrape-0.7.0.20230622-py3-none-any.whl (74 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-6.0.0-cp310-cp310-win_amd64.whl (4.0 MB)\n",
      "Collecting requests[socks]\n",
      "  Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl (107 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, soupsieve, PySocks, lxml, idna, filelock, charset_normalizer, certifi, requests, beautifulsoup4, snscrape\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.13.4 certifi-2025.8.3 charset_normalizer-3.4.3 filelock-3.19.1 idna-3.10 lxml-6.0.0 requests-2.32.5 snscrape-0.7.0.20230622 soupsieve-2.7 typing-extensions-4.14.1 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install snscrape\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0843b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FileFinder' object has no attribute 'find_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msnscrape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtwitter\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msntwitter\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([tweet\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m sntwitter\u001b[38;5;241m.\u001b[39mTwitterSearchScraper(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget_items()])\n",
      "File \u001b[1;32mc:\\Users\\yagne\\miniconda3\\Lib\\site-packages\\snscrape\\modules\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \t\tmodule \u001b[38;5;241m=\u001b[39m importer\u001b[38;5;241m.\u001b[39mfind_module(moduleName)\u001b[38;5;241m.\u001b[39mload_module(moduleName)\n\u001b[0;32m     14\u001b[0m \t\t\u001b[38;5;28mglobals\u001b[39m()[moduleNameWithoutPrefix] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m---> 17\u001b[0m \u001b[43m_import_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yagne\\miniconda3\\Lib\\site-packages\\snscrape\\modules\\__init__.py:13\u001b[0m, in \u001b[0;36m_import_modules\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m moduleNameWithoutPrefix \u001b[38;5;241m=\u001b[39m moduleName[prefixLen:]\n\u001b[0;32m     12\u001b[0m __all__\u001b[38;5;241m.\u001b[39mappend(moduleNameWithoutPrefix)\n\u001b[1;32m---> 13\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_module\u001b[49m(moduleName)\u001b[38;5;241m.\u001b[39mload_module(moduleName)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mglobals\u001b[39m()[moduleNameWithoutPrefix] \u001b[38;5;241m=\u001b[39m module\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FileFinder' object has no attribute 'find_module'"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([tweet.content for tweet in sntwitter.TwitterSearchScraper(\"AI\").get_items()])\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef307b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89be22de",
   "metadata": {},
   "source": [
    "# Reddit Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0e87c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Politics from r/politics...\n",
      "Scraping Economy from r/economics...\n",
      "Scraping Health from r/health...\n",
      "Scraping Sport from r/sports...\n",
      "Scraping Technology from r/technology...\n",
      "Scraping Entertainment from r/movies...\n",
      "Scraping Society from r/worldnews...\n",
      "Saved scraping results to reddit_data.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"xeV3sLrkl4xGyM-ScCBkSA\",\n",
    "    client_secret=\"sGrJQoAWabMp3hVcAXTxocV3gkCXoQ\",\n",
    "    user_agent=\"HeadlineHive\"\n",
    ")\n",
    "\n",
    "def scrape_reddit(subreddit, limit=100):\n",
    "    posts = []\n",
    "    for post in reddit.subreddit(subreddit).hot(limit=limit):\n",
    "        posts.append({\n",
    "            \"title\": post.title,\n",
    "            \"text\": post.selftext,\n",
    "            \"score\": post.score,\n",
    "            \"subreddit\": subreddit\n",
    "        })\n",
    "    return pd.DataFrame(posts)\n",
    "\n",
    "subs = {\n",
    "    \"Politics\": \"politics\",\n",
    "    \"Economy\": \"economics\",\n",
    "    \"Health\": \"health\",\n",
    "    \"Sport\": \"sports\",\n",
    "    \"Technology\": \"technology\",\n",
    "    \"Entertainment\": \"movies\",\n",
    "    \"Society\": \"worldnews\"\n",
    "}\n",
    "\n",
    "all_reddit = pd.DataFrame()\n",
    "for cat, sub in subs.items():\n",
    "    print(f\"Scraping {cat} from r/{sub}...\")\n",
    "    df = scrape_reddit(sub, limit=200)\n",
    "    df[\"category\"] = cat\n",
    "    all_reddit = pd.concat([all_reddit, df], ignore_index=True)\n",
    "\n",
    "all_reddit.to_csv(\"reddit_data.csv\", index=False)\n",
    "print(\"Saved scraping results to reddit_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3073b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
